<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bioperl on Perl.com - programming news, code and culture</title>
    <link>http://localhost:1313/tags/bioperl/</link>
    <description>Recent content in Bioperl on Perl.com - programming news, code and culture</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 20 Oct 2005 00:00:00 -0800</lastBuildDate>
    <atom:link href="/tags/bioperl/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Data Munging for Non-Programming Biologists</title>
      <link>http://localhost:1313/pub/2005/10/20/scriptome.html/</link>
      <pubDate>Thu, 20 Oct 2005 00:00:00 -0800</pubDate>
      
      <guid>http://localhost:1313/pub/2005/10/20/scriptome.html/</guid>
      <description>

&lt;p&gt;Have you ever renamed 768 files? Merged the content from 96 files into a spreadsheet? Filtered 100 lines out of a 20,000-line file?&lt;/p&gt;

&lt;p&gt;Have you ever done these things by hand?&lt;/p&gt;

&lt;p&gt;Disciples of laziness&amp;ndash;one of the three Perl programmer&amp;rsquo;s virtues&amp;ndash;know that you should never repeat anything five times, let alone 768. It dismayed me to learn that biologists do this kind of thing all the time.&lt;/p&gt;

&lt;h3 id=&#34;on-the-origin-of-scripts-the-problem&#34;&gt;On the Origin of Scripts: The Problem&lt;/h3&gt;

&lt;p&gt;Experimental biologists increasingly face large sets of large files in often-incompatible formats, which they need to filter, reformat, merge, and otherwise &lt;a href=&#34;http://www.catb.org/~esr/jargon/html/M/munge.html&#34;&gt;munge&lt;/a&gt; (definition 3). Biologists who can&amp;rsquo;t write Perl (most of them) often end up editing large files by hand. When they have the same problem a week later, &lt;em&gt;they do the same thing again&lt;/em&gt;&amp;ndash;or they just give up.&lt;/p&gt;

&lt;p&gt;My job description includes helping biologists to use computers. I could just write tailored, one-off scripts for them, right? As an answer, let me tell you about Neeraj. Neeraj is a typical NPB (non-programming biologist) who works down the hall. He came into my office, saying, &amp;ldquo;I have 12,000 sequences that I need to make primers for.&amp;rdquo; I said, &amp;ldquo;Make what?&amp;rdquo; (I haven&amp;rsquo;t been doing biology for very long.) Luckily, we figured out pretty quickly that all he wants to do is get characters 201-400 from each DNA sequence in a file. Those of you who have been Perling for a while can do this with your eyes closed (if you can touch type):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;perl -ne &#39;print substr($_, 200, 200), &amp;quot;\n&amp;quot;&#39; sequences.in &amp;gt;
    primers.out
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Voil√°! I gave Neeraj his output file and he went away, happy, to finish building his clone army to take over the world. (Or was he going to genetically modify rice to solve world hunger? I keep forgetting.)&lt;/p&gt;

&lt;p&gt;Unfortunately, that wasn&amp;rsquo;t the end. The next day, Neeraj came back, because he also wanted primers from the back end of the sequences (&lt;code&gt;substr($_, -400, 200)&lt;/code&gt;). Because he&amp;rsquo;s doing cutting-edge research, he may have totally different requirements next month, when he finishes his experiments. With just a few people in our group supporting hundreds or even thousands of biologists, writing tailored scripts, even quick one-liners, doesn&amp;rsquo;t scale. Other common solutions, such as teaching biologists Perl or creating graphical workflow managers, didn&amp;rsquo;t seem to fully address the data manipulation problem especially for occasional users, who won&amp;rsquo;t be munging every day.&lt;/p&gt;

&lt;p&gt;We need some tool that allows Neeraj, or any NPB, to munge his own data, rather than relying on (and explaining biology to) a programmer. Keeping the biologist in the loop this way gives him the best chance of applying the relevant data and algorithms to answer the right questions. The tool must be easy for a non-programmer to learn and to remember after a month harvesting fish eyes in Africa. It should also be TMTOWTDI-compliant, allowing him to play with data until he can sculpt it in the most meaningful way. While we&amp;rsquo;re at it, the tool will need to evolve rapidly as biologists ask new questions and create new kinds of data at an ever-increasing rate.&lt;/p&gt;

&lt;p&gt;When I told Neeraj&amp;rsquo;s story to others in our group, they said that they have struggled with this problem for years. During one of our brainstorming sessions, my not-so-pointy-haired boss, Eitan Rubin, said, &amp;ldquo;Wouldn&amp;rsquo;t it be nice if we could just give them a book of magical data-munging scripts that Just Work?&amp;rdquo; &amp;ldquo;Hm&amp;ndash;a sort of Script Tome?&amp;rdquo; And thus the Scriptome was born. (The joke here is that every self-respecting area of study in biology these days needs to have &amp;ldquo;ome&amp;rdquo; in its name: the genome, proteome, metabolome. There&amp;rsquo;s even a journal called &lt;em&gt;OMICS&lt;/em&gt; now.)&lt;/p&gt;

&lt;h3 id=&#34;harnessing-the-power-of-the-atom&#34;&gt;Harnessing the Power of the Atom&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://sysbio.harvard.edu/csb/resources/computational/scriptome/&#34;&gt;The Scriptome&lt;/a&gt; is a cookbook for munging biological data. The cookbook model nicely fits the UNIX paradigm of small tools that do simple operations. Instead of UNIX pipes, though, we encourage the use of intermediate files to avoid errors.&lt;/p&gt;

&lt;p&gt;We use a couple of tricks in order to make this cookbook accessible to NPBs. We use the familiar web browser as our GUI and harness the power of hyperlinking to develop a highly granular, hierarchical table of contents for the tools. This means we can include dozens to hundreds of tools, without requiring users to remember command names. Another trick is syntax highlighting. We gray out most of the Perl, to signify that reading it is optional. Parameters&amp;ndash;such as filenames, or maximum values to filter a certain column by&amp;ndash;we highlight in attention-getting red. Finally, we make a conscious effort to avoid computer science or invented terminology. Instead, we use language biologists find familiar. For example, tools are &amp;ldquo;atoms,&amp;rdquo; rather than &amp;ldquo;snippets.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;Each Scriptome tool consists of a Perl one-liner in a colored box, along with a couple of sentences of documentation (any more than that and no one will read it), and sample inputs and outputs. In order to use a tool, you:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Pick a tool type, perhaps &amp;ldquo;Choose&amp;rdquo; to choose certain lines or columns from a file.&lt;/li&gt;
&lt;li&gt;Browse a hierarchical table of contents.&lt;/li&gt;
&lt;li&gt;Cut and paste the code from the colored box onto a Unix, Mac OS X, or Windows command line. (Friendlier interfaces are in alpha testing&amp;ndash;a later section explains more.)&lt;/li&gt;
&lt;li&gt;Change red text as desired, using arrow keys or a text editor.&lt;/li&gt;
&lt;li&gt;Hit &lt;code&gt;Enter&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;That&amp;rsquo;s it!&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;100%&#34; /&gt;
&lt;/colgroup&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;p&gt;&lt;a href=&#34;http://localhost:1313/media/_pub_2005_10_20_scriptome/perl_com_pic.gif&#34;&gt;&lt;img src=&#34;http://localhost:1313/images/_pub_2005_10_20_scriptome/perl_com_pic_sm.gif&#34; alt=&#34;Figure 1&#34; width=&#34;300&#34; height=&#34;114&#34; /&gt;&lt;/a&gt;&lt;br /&gt;
Figure 1. A Scriptome tool for finding unique lines in a file--click image for full-size screen shot.&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The tool in Figure 1 reads the input line by line, using Perl&amp;rsquo;s &lt;code&gt;-n&lt;/code&gt; option, and prints each line only when it sees the value in a given, user-editable column for the first time. The substitution removes a newline, even if it&amp;rsquo;s a Windows file being read on a UNIX machine. Then the line is split on tabs. A hash keeps track of unique values in the given column, deciding which lines to print. Finally, the script prints to the screen a very quick diagnostic, specifically how many lines it chose out of how many total lines it read. (Choosing all lines or zero lines may mean you&amp;rsquo;re not filtering correctly.)&lt;/p&gt;

&lt;p&gt;By cutting and pasting tools like this, a biologist can perform basic data munging operations, without any programming knowledge or program installation (except for ActivePerl on Windows). Unfortunately, that&amp;rsquo;s still not really enough to solve real-world problems.&lt;/p&gt;

&lt;h3 id=&#34;splicing-the-scriptome&#34;&gt;Splicing the Scriptome&lt;/h3&gt;

&lt;p&gt;As it happens, the story I told you about Neeraj earlier wasn&amp;rsquo;t entirely accurate. He actually wanted to print both the beginning and ending substrings from his sequences. Also, his input was in the common FASTA format, where each sequence has an ID line like &lt;code&gt;&amp;gt;A2352334&lt;/code&gt; followed by a variable number of lines with DNA letters. We don&amp;rsquo;t have one tool that parses FASTA and takes out two different substrings; writing every possible combination of tools would take even longer than writing Perl 6 (ahem). Instead, again following UNIX, we leave it up to the biologist to combine the tools into problem-specific solutions. In this case, that solution would involve using the FASTA-to-table converter, followed by a tool to pull out the sequence column, and then two copies of the substring tool.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;re asking biologists to break a problem down into pieces&amp;ndash;each of which is solvable using some set of tools&amp;ndash;and then to string those tools together in the right order with the right parameters. That sounds an awful lot like programming, doesn&amp;rsquo;t it? Although you may not think about it anymore, some of the fundamental concepts of programming are new and difficult. Luckily, it turns out that biologists learned more in grad school than how to extract things out of (reluctant) other things. In fact, they already know how to break down problems, loop, branch, and debug; instead of programming, though, they call it developing protocols. They also already have &lt;a href=&#34;http://www.molecularcloning.com/public/tour/index.html&#34;&gt;cookbooks for experimental molecular biology&lt;/a&gt;. Such a protocol might include lines like:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Add 1 ml of such-and-such enzyme to the DNA.&lt;/li&gt;
&lt;li&gt;Incubate test tube at 90 degrees C for an hour.&lt;/li&gt;
&lt;li&gt;If the mixture turns clear, goto step 5.&lt;/li&gt;
&lt;li&gt;Repeat steps 2-3 three times.&lt;/li&gt;
&lt;li&gt;Pour liquid into a sterile bottle &lt;em&gt;very carefully&lt;/em&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;We borrowed the term &amp;ldquo;protocol&amp;rdquo; to describe an ordered set of parameterized Scriptome tools that solves a larger problem. (The right word for this is a script, but don&amp;rsquo;t tell our users&amp;ndash;they might realize they&amp;rsquo;re learning how to program.) We feature some pre-written protocols on the website. Note that because each tool is a command-line command, a set of them together is really just an executable shell script.&lt;/p&gt;

&lt;p&gt;The Scriptome may be even more than a high-level, mostly syntax-free, non-toy language for NPBs. Because it exposes the Perl directly on the website&amp;ndash;giving new meaning to the term &amp;ldquo;open source&amp;rdquo;&amp;ndash;some curious biologists may even start reading the short, simple, relevant examples of Perl code. (Unfortunately, putting the command into one line makes it harder to read. One of our TODOs is an Explain button next to each tool, which would show you a commented, multi-line version of each script.) From there, it&amp;rsquo;s a short hop to tweaking the tools, and before you know it, we&amp;rsquo;ll have more annoying newbie posts on &lt;em&gt;comp.lang.perl.misc&lt;/em&gt;!&lt;/p&gt;

&lt;h3 id=&#34;intelligent-design-the-geeky-details&#34;&gt;Intelligent Design: The Geeky Details&lt;/h3&gt;

&lt;p&gt;If you&amp;rsquo;ve read this far, you may have realized by now that the Scriptome is not a programming project at heart. Design, interface, documentation, and examples are as important as the programming itself, which is pretty easy. This being an article on Perl.com, though, I want to discuss the use of Perl throughout the project.&lt;/p&gt;

&lt;h4 id=&#34;why-perl&#34;&gt;Why Perl?&lt;/h4&gt;

&lt;p&gt;Several people asked me why we didn&amp;rsquo;t write the Scriptome in Python, or R, or just use UNIX &lt;code&gt;sh&lt;/code&gt; for everything. Well, other than the obvious (&amp;ldquo;It&amp;rsquo;s the One True Language!&amp;rdquo;), Perl data munges by design, it&amp;rsquo;s great for fast tool development, it&amp;rsquo;s portable to many platforms, and it&amp;rsquo;s already installed on every Unix and Mac OS X box. Moreover, the &lt;a href=&#34;http://bioperl.org/&#34;&gt;Bioperl&lt;/a&gt; modules offer me a huge number of tools to steal, um, reuse. Finally, Perl is the preferred language of the entire Scriptome development team (me).&lt;/p&gt;

&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;100%&#34; /&gt;
&lt;/colgroup&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;div class=&#34;secondary&#34;&gt;
&lt;h4 id=&#34;what-kind-of-perl&#34; align=&#34;center&#34;&gt;What kind of Perl?&lt;/h4&gt;
&lt;p&gt;Perl allows you to write pretty impressive tools in only a couple of hundred characters, with Perl Golf tricks such as the &lt;code&gt;-n&lt;/code&gt; option, autovivification, and the implicit &lt;code&gt;$_&lt;/code&gt; variable. On the other hand, we want the code to be readable, especially if we want newbies to learn from it, so we can&#39;t use too many Golf shortcuts. (For example, here&#39;s the winning solution in the Perl Golf contest for a script to find the last non-zero digit of N factorial by Juho Snellman:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; #!perl -l $_*=$`%9e9,??for+1=~?0*$?..pop;print$`%10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Some might consider this difficult for newbies to read.)&lt;/p&gt;
&lt;/div&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&#34;the-scriptome-build&#34;&gt;The Scriptome Build&lt;/h4&gt;

&lt;p&gt;Even though we&amp;rsquo;re trying to keep the tools pretty generic and simple, we know we&amp;rsquo;ll need several dozen at least, to be at all useful. In addition, data formats and biologists&amp;rsquo; interests will change over time. We knew we had to make the process of creating a new tool fast and automatic.&lt;/p&gt;

&lt;p&gt;I write the tool pages in POD, which lets me use Vim rather than a fancy web-page editor. My Makefile runs &lt;code&gt;pod2html&lt;/code&gt; to create a nice, if simple, web page that includes the table of contents for free. A Perl filter then adds a navigation bar and some simple interface-enhancing JavaScript, and makes the parameters red. I may give in and switch to a templating system, database back end, or XML eventually, and automated testing would be great. For now, keeping it simple means I can create, test, document, and publish a new tool in under an hour. (Okay, I didn&amp;rsquo;t include debugging in that time.)&lt;/p&gt;

&lt;h4 id=&#34;perl-culture&#34;&gt;Perl Culture&lt;/h4&gt;

&lt;p&gt;There&amp;rsquo;s lots of Perl code in the project, but I&amp;rsquo;m trying to incorporate some Perl &lt;em&gt;attitude&lt;/em&gt; as well. The &amp;ldquo;Aha!&amp;rdquo; moment of the Scriptome came when we realized we could just post a bunch of hacked one-liners on the Web to help biologists &lt;em&gt;now&lt;/em&gt;, rather than spend six or 12 months crafting the perfect solution. While many computational biologists focus on writing O(N) programs for sophisticated sequence analysis or gene expression studies, we&amp;rsquo;re not ashamed to write glue instead; we solve the unglamorous problem of taking the output from their fancy programs and throwing it into tabular format, so that a biologist can study the results in Excel. After all, if data munging is even one step in Neeraj&amp;rsquo;s pipeline, then he still can&amp;rsquo;t get his paper published without these tools. Finally, we&amp;rsquo;re listening aggressively to our users, because only they can tell us which easy things to make easy and which hard things to make possible.&lt;/p&gt;

&lt;h3 id=&#34;filling-the-niche-the-scriptome-and-other-solutions&#34;&gt;Filling the Niche: The Scriptome and Other Solutions&lt;/h3&gt;

&lt;p&gt;One of my greatest concerns in talking to people about biologists&amp;rsquo; data munging is that people don&amp;rsquo;t even realize that there&amp;rsquo;s a problem, or they think it&amp;rsquo;s already been solved. Biologists&amp;ndash;who happily pipette things over and over and over again&amp;ndash;don&amp;rsquo;t realize that computers could save them lots of time. Too many programmers figure that anyone who needs to can just read &lt;em&gt;Learning Perl&lt;/em&gt;. I&amp;rsquo;m all for that, of course, but experimental biologists need to spend much more of their time getting data (dissecting bee brains, say) than analyzing it, so they can&amp;rsquo;t afford the time it takes to become programmers. They shouldn&amp;rsquo;t have to. Does the average biologist need multiple inheritance, &lt;code&gt;getprotobyname()&lt;/code&gt;, and negative look-behind regexes? There&amp;rsquo;s a large body of problems out there that are too diverse for simple, inflexible tools to handle, but are too simple to need full-fledged programming.&lt;/p&gt;

&lt;p&gt;How about teaching a three-hour course with just enough Perl to munge simple data? At minimum, it should teach variables, arrays, hashes, regular expressions, and control structures&amp;ndash;and then there&amp;rsquo;s syntax. &amp;ldquo;Wait, what&amp;rsquo;s the difference between &lt;code&gt;@{$a[$a]}&lt;/code&gt; and &lt;code&gt;@a{$a[$a]}&lt;/code&gt; again?&amp;rdquo; &amp;ldquo;Oh, my, look at the time.&amp;rdquo; As Damian Conway writes in &amp;ldquo;&lt;a href=&#34;http://www.csse.monash.edu.au/~damian/papers/PDF/SevenDeadlySins.pdf&#34;&gt;Seven Deadly Sins of Introductory Programming Language Design&lt;/a&gt;&amp;rdquo; (PDF link), syntax oddities often distract newbies from learning basic programming concepts. How much can you teach in three hours, and how much will they remember after a month without practicing?&lt;/p&gt;

&lt;p&gt;Another route would be building a graphical program that can do everything a biologist would want, where pipelines are developed by dragging and dropping icons and connectors. Unfortunately, a comprehensive graphical environment requires a major programming effort to build, and to keep current. Not only that, but the interface for such a full-featured, graphical program will necessarily be complex, raising the learning barrier.&lt;/p&gt;

&lt;p&gt;In building the Scriptome, we purposely narrowed our scope, to maximize learnability and memorability for occasional users. While teaching programming and graphical tools are effective solutions for some, I believe the Scriptome fills an empty niche in the data munging ecosphere (the greposphere?).&lt;/p&gt;

&lt;h3 id=&#34;creation-is-not-easy&#34;&gt;Creation Is Not Easy&lt;/h3&gt;

&lt;p&gt;How much progress have we made in addressing the problem space between tool use and programming? Our early reviews have been mostly positive, or at least constructive. Suzy, our first power user, started out skeptical, saying she&amp;rsquo;d probably have to learn Perl because any tools we gave her wouldn&amp;rsquo;t be flexible enough. I encouraged her to use the Scriptome in parallel with learning Perl. She ended up a self-described &amp;ldquo;Scriptome monster,&amp;rdquo; tweaking tool code and creating a 16-step protocol that did real bioinformatics. Still, one good review won&amp;rsquo;t get you any Webby awards. Our first priority at this point is to build a user base and to get feedback on the learnability, memorability, and effectiveness of the website, with its 50 or so tools.&lt;/p&gt;

&lt;p&gt;It will take more than just feedback to implement the myriad ideas we have for improving the Scriptome, which is why I&amp;rsquo;m here to make a bald-faced plea for your help. The project needs lots of new tools, new protocols, and possibly new interfaces. You, the Perl.com reader, can certainly write code for new tools; the real question is whether you (unlike certain, unnamed CPAN contributors) can also write good documentation and examples, or find bugs in early versions of tools. We would also love to get relevant protocol ideas. Check out the &lt;a href=&#34;https://bioinformatics.org/project/?group_id=505&#34;&gt;Scriptome project page&lt;/a&gt; and send something to me or the &lt;em&gt;scriptome-users&lt;/em&gt; mailing list.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s a little challenge. I really did have a client who renamed 768 files by hand before I could Perl it for him. Can you write a generic renaming atom that a NPB could use? (Hint: &amp;ldquo;Tell the user to learn regular expressions&amp;rdquo; is not a valid solution.) The winner will receive a commemorative plaque (&lt;code&gt;&amp;lt;bgcolor=&amp;quot;gold&amp;quot;&amp;gt;&lt;/code&gt;) on the Scriptome website.&lt;/p&gt;

&lt;p&gt;Speaking of new interfaces, one common concern we hear from programmers is that NPBs won&amp;rsquo;t be able or willing to handle the command-line paradigm shift and the few commands needed (&lt;code&gt;cd&lt;/code&gt;, &lt;code&gt;more&lt;/code&gt;, &lt;code&gt;dir/ls&lt;/code&gt;) to use the Scriptome. In case our users do tell us it&amp;rsquo;s a problem, we&amp;rsquo;re exploring a few different ways to wrap the Scriptome tools, such as:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A Firefox plugin that gives you a command line in a toolbar and displays your output file in the browser. (Currently being developed by Rob Miller and his group at MIT.)&lt;/li&gt;
&lt;li&gt;An Excel VBA that lets you put command lines into a column, and creates a shell script out of it.&lt;/li&gt;
&lt;li&gt;Wrapping the command-line tools in &lt;a href=&#34;http://www.pasteur.fr/recherche/unites/sis/Pise/&#34;&gt;Pise&lt;/a&gt; (web forms around shell commands) or &lt;a href=&#34;http://www.genepattern.org/&#34;&gt;GenePattern&lt;/a&gt; (a more general GUI bio tool).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We&amp;rsquo;ll probably try several of these avenues, because they allow us to keep using the command-line interface if desired.&lt;/p&gt;

&lt;p&gt;As for the future, well, who says that only biologists are interested in munging tabular data? Certainly, chemists and astronomers could get into this. I set my sights even higher. How about a Scriptome for a business manager wanting to munge reports? An Apache Scriptome to munge your website&amp;rsquo;s access logs? An iTunes Scriptome to manage your music? Let&amp;rsquo;s give users the power to do what they want with their data.&lt;/p&gt;

&lt;p&gt;Sorry, &lt;em&gt;GUI Neanderthalis&lt;/em&gt;, but you can&amp;rsquo;t adapt to today&amp;rsquo;s data munging needs. Make room for &lt;em&gt;Homo Scriptiens&lt;/em&gt;!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Chromosome at a Time with Perl, Part 2</title>
      <link>http://localhost:1313/pub/2003/10/15/bioinformatics.html/</link>
      <pubDate>Wed, 15 Oct 2003 00:00:00 -0800</pubDate>
      
      <guid>http://localhost:1313/pub/2003/10/15/bioinformatics.html/</guid>
      <description>

&lt;p&gt;&lt;em&gt;James D. Tisdall is the author of the recently released&lt;/em&gt; &lt;a href=&#34;http://www.oreilly.com/catalog/mperlbio/index.html?CMP=IL7015&#34;&gt;Mastering Perl for Bioinformatics&lt;/a&gt;&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In my previous article, &lt;a href=&#34;http://localhost:1313/pub/2003/09/10/bioinformatics.html&#34;&gt;A Chromosome at a Time with Perl, Part I&lt;/a&gt;, I showed you some programming &amp;ldquo;tricks&amp;rdquo; that help you avoid the trap of using up all your main memory when coding for very long strings, such as chromosomes and entire genomes.&lt;/p&gt;

&lt;p&gt;The basic approach involved improving your code&amp;rsquo;s running time by limiting the amount of memory space the program uses. The tricks discussed were calling subroutines with references as arguments, and searching for a pattern in a very large file by keeping only a small &amp;ldquo;window&amp;rdquo; of the file in memory at any one time, in a buffer.&lt;/p&gt;

&lt;p&gt;This article will continue that discussion. I&amp;rsquo;ll show you more about how references can greatly speed up a subroutine call by avoiding making copies of very large strings. I&amp;rsquo;ll show you how you can bypass the overhead of subroutine calls entirely. I&amp;rsquo;ll extend the previous example of a buffer window into a large file, making it suited to any situation where you know the minimum and maximum length of a pattern for which you&amp;rsquo;re searching. And I&amp;rsquo;ll show you how to quantify the behavior of your code by measuring its speed and space usage.&lt;/p&gt;

&lt;h3 id=&#34;why-space-puts-a-lower-bound-on-time&#34;&gt;Why Space Puts a Lower Bound on Time&lt;/h3&gt;

&lt;p&gt;In Perl, as in any programming system, the size of the data that the program uses is an absolute lower bound on how fast the program can perform.&lt;/p&gt;

&lt;p&gt;In fact, algorithms are typically classified by how fast they perform on inputs of varying sizes, by giving their speed as a function of the size of the input. So a program that has to do &lt;strong&gt;2&lt;sup&gt;n&lt;/sup&gt;&lt;/strong&gt; computations on an input of size &lt;strong&gt;n&lt;/strong&gt; is a hell of a lot slower than a program that has to do &lt;strong&gt;n&lt;sup&gt;2&lt;/sup&gt;&lt;/strong&gt; computations on an input of size &lt;strong&gt;n&lt;/strong&gt;. The first is called &lt;em&gt;intractable&lt;/em&gt; and &lt;em&gt;exponential&lt;/em&gt;, or &amp;ldquo;bad&amp;rdquo;; the second is called &lt;em&gt;tractable&lt;/em&gt; and &lt;em&gt;polynomial&lt;/em&gt;, or &amp;ldquo;good.&amp;rdquo; For instance, if &lt;strong&gt;n&lt;/strong&gt;, the size of the input, is 100, then &lt;strong&gt;n&lt;sup&gt;2&lt;/sup&gt;&lt;/strong&gt; is 10,000, while &lt;strong&gt;2&lt;sup&gt;n&lt;/sup&gt;&lt;/strong&gt; is bigger than the number of atoms in the universe. But who&amp;rsquo;s counting? And is the universe really finite? Oh well &amp;hellip; back to your regularly scheduled program.&lt;/p&gt;

&lt;p&gt;This way of measuring an algorithm is called &lt;em&gt;time complexity&lt;/em&gt;. It&amp;rsquo;s usually written in a shorthand called &lt;em&gt;big Oh&lt;/em&gt; notation. (See the Suggested Reading at the end of this article, if you get that far.)&lt;/p&gt;

&lt;p&gt;In particular, if an algorithm gets an input of size &lt;strong&gt;n&lt;/strong&gt;, and then just to write the answer it must write an output of size &lt;strong&gt;2&lt;sup&gt;n&lt;/sup&gt;&lt;/strong&gt;, then the algorithm is taking &lt;strong&gt;2&lt;sup&gt;n&lt;/sup&gt;&lt;/strong&gt; time, at least. So the space that an algorithm uses is intimately connected to the time it uses. Of course, a program could use just a small, constant amount of space and still use &lt;strong&gt;2&lt;sup&gt;n&lt;/sup&gt;&lt;/strong&gt; time, for instance if it added and subtracted the number one over and over, &lt;strong&gt;2&lt;sup&gt;n&lt;/sup&gt;&lt;/strong&gt; times, for some perverse reason. Still, the amount of space that an algorithm uses establishes a lower bound for how much time the algorithm takes to complete.&lt;/p&gt;

&lt;p&gt;What&amp;rsquo;s all this got to do with Perl programming in bioinformatics? Quite a lot, if you&amp;rsquo;re writing code that manipulates, say, the 3 gigabases of human DNA.&lt;/p&gt;

&lt;p&gt;If you&amp;rsquo;re new to the field, a base is one of the letters A, C, G, or T that represents one of the four molecules that are the principal building blocks of DNA. Each base is typically represented in a computer language as one ASCII character taking one 8-bit byte, so 3 gigabases equals 3 gigabytes. Of course, you could represent each of the four bases using only 2 bits, so considerable compression is possible; but such space efficiency is not commonly employed. Hmmm &amp;hellip; makes an interesting idea for another article, however! &amp;ldquo;Perl and a Chromosome, Two Bits.&amp;rdquo; Watch this space.&lt;/p&gt;

&lt;p&gt;Just to read in the 3 gigabytes of DNA is going to take you some time. If you&amp;rsquo;re also making copies of the 3 gigabytes in your variables, you&amp;rsquo;re going to need more main memory than most computers have available. So the crafty Perl programmer needs to think of programming solutions that minimize the amount of space used when computing with such large input. If she does, not only will she have a program that fits into her computer&amp;rsquo;s memory (always a wise move); she may also have a program that runs pretty fast, if she does say so herself, with all due humility.&lt;/p&gt;

&lt;h3 id=&#34;subroutines-without-extra-space&#34;&gt;Subroutines Without Extra Space&lt;/h3&gt;

&lt;p&gt;In Part I, I briefly discussed how passing references to subroutines can save you considerable space. I&amp;rsquo;ll just expand a little on that discussion in this section. There are three main ways that references can be used to save space and therefore time in the subroutines of your Perl program.&lt;/p&gt;

&lt;h4 id=&#34;one-collect-data-in-a-subroutine-argument&#34;&gt;One: Collect Data in a Subroutine Argument&lt;/h4&gt;

&lt;p&gt;First, let&amp;rsquo;s say you call a subroutine to get some data. Typically this takes a form such as this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;my $chromosome1 = get_chromosome( 1 );
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Assuming that the data is about 100 megabases long, the Perl programmer can see that the subroutine &amp;ldquo;get_chromosome&amp;rdquo; is collecting 100 megabases of DNA and then &amp;ldquo;returning&amp;rdquo; it, which means that copies of those 100 megabases are being made. And that&amp;rsquo;s a Bad Thing.&lt;/p&gt;

&lt;p&gt;Instead, the wily hacker could pass a reference to the &lt;code&gt;$chromosome1&lt;/code&gt; string into the subroutine, which could be written to &amp;ldquo;fill&amp;rdquo; the string with the 100 megabases without the need for further copying. Then after the subroutine call, say like so:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;get_chromosome(1, \$chromosome1);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;the variable &lt;code&gt;$chromosome1&lt;/code&gt; would contain the same data as in the previous version, but it would have gotten there without being copied by means of being &amp;ldquo;returned&amp;rdquo; from a subroutine. And that&amp;rsquo;s a Good Thing. The only gotcha here is that the subroutine call is definitely changing what&amp;rsquo;s in the &lt;code&gt;$chromosome1&lt;/code&gt; variable. No problem as long as you remember that&amp;rsquo;s what&amp;rsquo;s happening.&lt;/p&gt;

&lt;h4 id=&#34;two-pass-the-subroutine-a-reference-to-the-data&#34;&gt;Two: Pass the Subroutine a Reference to the Data&lt;/h4&gt;

&lt;p&gt;Here&amp;rsquo;s a second way to use references as subroutine arguments to good advantage. Let&amp;rsquo;s say you have a chromosome&amp;rsquo;s worth of DNA in a variable&lt;code&gt;$chromosome1&lt;/code&gt;, and you want to pass it to a subroutine that counts how many As, Cs, Gs, and Ts there are in it. (This might be important if you were looking for genes in the chromosome, for instance &amp;ndash; in humans, genes tend to be GC rich.)&lt;/p&gt;

&lt;p&gt;If you write your code like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;my($a, $c, $g, $t) = countacgt( $chromosome1 );
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;then the &amp;ldquo;countacgt&amp;rdquo; subroutine is going to make a copy of the data in the argument &lt;code&gt;$chromosome1&lt;/code&gt;. That&amp;rsquo;s a Regrettable Occurence.&lt;/p&gt;

&lt;p&gt;On the other hand, if you pass the subroutine a &lt;em&gt;reference&lt;/em&gt; to the data in &lt;code&gt;$chromosome1&lt;/code&gt;, the data will not be copied, and that&amp;rsquo;s a Fortunate Happenstance:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;my($a, $c, $g, $t) = countacgt( \$chromosome1 );
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;However, once again you&amp;rsquo;ll have to be aware that the subroutine has the power to change what&amp;rsquo;s in the &lt;code&gt;$chromosome1&lt;/code&gt; variable, and either avoid changing it or take note of the change.&lt;/p&gt;

&lt;p&gt;As another alternative, you could use&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;my($a, $c, $g, $t) = countacgt( $chromosome1 );
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;but then &lt;em&gt;don&amp;rsquo;t&lt;/em&gt; assign a new variable to the argument within the &lt;code&gt;countacgt&lt;/code&gt; subroutine, like so:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;my($chrom) = @_;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Instead, just use &lt;code&gt;$_[0]&lt;/code&gt; to access the chromosome data without copying it. And that&amp;rsquo;s a Perl Idiom. (For readability, you may want to add a comment explaining what kind of data &lt;code&gt;$_[0]&lt;/code&gt; is, since you won&amp;rsquo;t have an informative variable name.)&lt;/p&gt;

&lt;h4 id=&#34;three-return-a-reference-to-the-data&#34;&gt;Three: Return a Reference to the Data&lt;/h4&gt;

&lt;p&gt;Now a third and final way to use references instead of space: if you have a subroutine that collects a large amount of data, you can have it return a reference to the data instead of the data itself; this will also avoid the large string copies, which Ain&amp;rsquo;t Bad:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;my $chromosome1ref = get_chromosome( 1 );
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;eliminating-subroutines-altogether&#34;&gt;Eliminating Subroutines Altogether&lt;/h3&gt;

&lt;p&gt;Organizing the code for a computation into a logical set of subroutines can make for clean, easy-to-understand, and elegant programming.&lt;/p&gt;

&lt;p&gt;Unfortunately, it can also make your program perform much slower. Take this small example. (An &lt;em&gt;exon&lt;/em&gt; is a stretch of a chromosome&amp;rsquo;s DNA, transcribed into RNA, that contains part of the code for a gene. In organisms such as humans, most genes are composed of multiple exons separated by non-coding &lt;em&gt;introns&lt;/em&gt;; the exons are &lt;em&gt;spliced&lt;/em&gt; together to get the actual code for the gene):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;while ((my $begin, my $end) =  each %exon_endpoints) {
    print get_exon($chromosome, $begin, $end), &amp;quot;\n\n&amp;quot;;
}

sub get_exon {
    my($chromosome, $begin, $end) = @_;

    # The arguments to substr are: string, beginning, length
    return substr($chromosome, $begin - 1, $end - $begin + 1);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This code takes the information about exon endpoints stored in the hash &lt;code&gt;%exon_endpoints&lt;/code&gt; (key = begin, value = end) to extract the exons from a chromosome and print them. (You may remember from Part I that I translated between the Perl idea of location, where the first location of a string is position 0, and the biologist&amp;rsquo;s idea of location, where the first location is position 1.) The code is short, to the point, and gets the job done. &lt;strong&gt;Unfortunately, it also makes as many copies of the entire chromosome as there are exons to print out&lt;/strong&gt;. &lt;em&gt;Ouch.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In such circumstances, you can save a boatload of pain by eliminating the subroutine entirely, like so:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;while ((my $begin, my $end) =  each %exon_endpoints) {
    print substr($chromosome, $begin - 1, $end - $begin + 1), &amp;quot;\n\n&amp;quot;;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The bad news: now the details of how to extract the desired exon from the chromosome are right in the loop, instead of being nicely tucked away in the subroutine &lt;code&gt;get_exon&lt;/code&gt;. The good news: the program will finish running before the weekend.&lt;/p&gt;

&lt;h3 id=&#34;sequence-motifs-with-bounded-lengths&#34;&gt;Sequence Motifs with Bounded Lengths&lt;/h3&gt;

&lt;p&gt;In Part I, I showed you how to search for a small pattern in a very large file of DNA data (in &lt;em&gt;FASTA&lt;/em&gt; format) by only keeping at most two lines of the file in the program&amp;rsquo;s memory at any one time.&lt;/p&gt;

&lt;p&gt;Here is some code that generalizes that approach. It is more general because it allows you to declare the maximum and minimum pattern sizes. It uses no more than a certain maximum amount of main memory for the data at any one time. For instance, if you&amp;rsquo;re looking for a pattern and you know that any match must be between 300 and 2,000 bases long, you can use this subroutine to search any amount of DNA while keeping the amount of main memory used for the DNA to within about 4,000 bytes, twice the maximum pattern size. Only matching patterns between 300 and 2,000 bases long will be reported.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#!/usr/bin/perl
#
# find_size_bounded_pattern : find a pattern known to be between a min and max length
#   Keep small size of memory but handle arbitrarily large input files
#
#  Copyright (c) 2003 James Tisdall
#

use warnings;
use strict;
use Carp;

my $pattern  = &amp;quot;GGTGGAC[GT].{50,1500}[AC][GT][CG]ATAT&amp;quot;;
my $filename = &amp;quot;Fly.dna&amp;quot;;
my $min      = 65;
my $max      = 1515;

my @locations = find_size_bounded_pattern($pattern, $filename, $min, $max);

print &amp;quot;@locations\n&amp;quot;;

exit;

### End of main program
##################################################

##################################################
### Subroutines:

sub find_size_bounded_pattern {

    ################# Arguments:
    # $pattern   - the pattern to search for, as a regular _expression
    # $filename  - the name of the DNA fasta file (may have multiple records)
    # $min       - the shortest length of a usable match to the pattern
    # $max       - the longest length of a usable match to the pattern
    #################
    my($pattern, $filename, $min, $max) = @_;

    ################# Other variables:
    # $buffer    - a buffer to store the DNA text, usually (2 * $max) in length
    # $position  - the position of the beginning of the buffer in the DNA
    # @locations - the locations where the pattern was found, to be returned
    #              @locations also includes headers for each fasta record
    # $header    - the one-line fasta header for each record in a fasta file
    my $buffer = &#39;&#39;;
    my $position = 0;
    my @locations = ();
    my $header = &#39;&#39;;
    #################

    # Open the DNA file
    open(DNA,&amp;quot;&amp;lt;$filename&amp;quot;) or croak(&amp;quot;Cannot open $filename:$!\n&amp;quot;);

    # Get the input lines and compute
    while(my $newline = &amp;lt;DNA&amp;gt; ) {

        # If new fasta header, reinitialize buffer and location counter
        if($newline =~ /^&amp;gt;/) {
            # Complete previous search in buffer which contains end of fasta record
            while($buffer =~ /$pattern/gi) {
                if($-[0] &amp;lt;= length($buffer) - $min) {
                    unless(($+[0] - $-[0] &amp;lt; $min) or ($+[0] - $-[0] &amp;gt; $max)) {
                        push(@locations, $position + $-[0] + 1);
                    }
                }
            }
            # Reset $header, $buffer, $position for new fasta record
            $header = $newline;
            push(@locations, &amp;quot;\n$header&amp;quot;);
            buffer = &#39;&#39;;
        $position = 0;

            # Get new line from file
            next;
        }

        # If new line of DNA data

        # Add the new line to the buffer
        chomp $newline;
        $buffer .= $newline;

        if(length($buffer) &amp;lt; (2 * $max) ) {
            next;
        }

        # Search for the DNA pattern
        # (Report the character at position 0 as at position 1, as usual in biology)
        while($buffer =~ /$pattern/gi) {
            if($-[0] &amp;lt; $max) {
                unless(($+[0] - $-[0] &amp;lt; $min) or ($+[0] - $-[0] &amp;gt; $max)) {
                    push(@locations, $position + $-[0] + 1);
                }
            }else{
                last;
            }
        }

        # Reset the position counter
        # (will be accurate after you reset the buffer, next)
        $position = $position + $max;

        # Reset the buffer
        # Discard the first $max worth of data in the buffer
        $buffer = substr($buffer, $max);
    }

    # Complete search in final buffer
    while($buffer =~ /$pattern/gi) {
        if($-[0] &amp;lt;= length($buffer) - $min) {
            unless(($+[0] - $-[0] &amp;lt;$min) $-[0] ($+[0] - or&amp;gt; $max)) {
                push(@locations, $position + $-[0] + 1);
            }
        }
    }

    # Computation complete
    return @locations;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;how-the-code-works&#34;&gt;How the Code Works&lt;/h3&gt;

&lt;p&gt;This code gets its DNA from a FASTA-formatted file (FASTA is the most common format for a file of DNA sequence data). It would be fairly easy to rewrite this so that you could give multiple FASTA filenames on a command line and all the files would be processed by this code. As it is, it can handle a single FASTA file that contains multiple FASTA records.&lt;/p&gt;

&lt;p&gt;The subroutine &lt;code&gt;find_size_bounded_pattern&lt;/code&gt; returns an array of all the locations in the DNA that contain the pattern. Since the input may have several FASTA records, the one-line header of each record is also returned, to help identify the start of each new record. For instance, I tested this program on a file, &lt;code&gt;Fly.dna&lt;/code&gt;, that contains all the chromosomes of the fruit fly, &lt;em&gt;Drosophila melanogaster&lt;/em&gt;. In this file, each new chromosome begins with a new FASTA header, which is added to the returned array. The locations reported start afresh from 1 for each chromosome.&lt;/p&gt;

&lt;p&gt;The pattern to be searched for is only reported if it&amp;rsquo;s between a certain minimum and maximum length. Twice the maximum desired pattern length (plus the length of an input line) is the limit of the amount of DNA data that is read into the program&amp;rsquo;s buffer. That way you can search a &lt;code&gt;$max&lt;/code&gt; worth of DNA for the beginning locations of patterns that may be up to &lt;code&gt;$max&lt;/code&gt; long.&lt;/p&gt;

&lt;p&gt;The overall structure of this code is pretty simple, and the comments in the code should do most of the explaining. There are two situations dealt with in the loop as it reads input lines. First is when there is a new FASTA header. Then you have to finish searching in the buffer, and reset the variables to begin a search in a new sequence of DNA from a new FASTA record. Second is when there is a new line of DNA. And finally, after all the lines have been read and you exit the loop, there may still be some unsearched DNA in the buffer, so the subroutine ends by searching the DNA remaining in the last buffer.&lt;/p&gt;

&lt;p&gt;In this code, the devil is in the details of how the specific locations and sizes are set. The intermediate level Perl programmer should be able to puzzle this out given the comments in the code. Note that after a successful pattern match the builtin variable &lt;code&gt;$-[0]&lt;/code&gt; has the offset of the beginning of the match, and &lt;code&gt;$+[0]&lt;/code&gt; has the offset of the end of the match. This avoids the use of the special variable &lt;code&gt;$&amp;amp;&lt;/code&gt;, the use of which causes all manner of space to be used to hold this and several other special variables. But if your regular expression has any parentheses, that&amp;rsquo;s enough to make the special variables and their considerable space get used too. Of course, regular expressions have their own rules of behavior, such as greedy matching and so forth, that are not addressed by this code. (Could you modify this program to find patterns that overlap each other? What happens if &lt;code&gt;$max&lt;/code&gt; is less than the input line size? What other assumptions are made by this code?)&lt;/p&gt;

&lt;h3 id=&#34;profiling-the-speed-of-your-perl-program&#34;&gt;Profiling the Speed of your Perl Program&lt;/h3&gt;

&lt;p&gt;You can profile the speed of your Perl program fairly easily. Let&amp;rsquo;s say I put the program in a file called &lt;em&gt;sizebound.pl&lt;/em&gt;. Then I can get a report on the time the various parts of the program require by running the program like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[tisdall@coltrane]$ perl -d:DProf sizebound.pl
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And then getting a summary of the report (from the file tmon.out that DProf creates) like so:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[tisdall@coltrane]$ dprofpp
Total Elapsed Time =  95.1899 Seconds
  User+System Time =  94.9099 Seconds
Exclusive Times
%Time ExclSec CumulS #Calls sec/call Csec/c  Name
 99.9   94.87 94.870      1   94.870 94.870  main::find_size_bounded_pattern
 0.02   0.020  0.020      3   0.0067 0.0067  main::BEGIN
 0.00   0.000 -0.000      1   0.0000      -  warnings::BEGIN
 0.00   0.000 -0.000      2   0.0000      -  Exporter::import
 0.00   0.000 -0.000      1   0.0000      -  warnings::import
 0.00   0.000 -0.000      1   0.0000      -  strict::import
 0.00   0.000 -0.000      1   0.0000      -  strict::bits
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When you have lots of subroutines, this can really help you see where the most time is being spent. Here, I&amp;rsquo;m really just getting the information that the program took about a minute and a half to look for the pattern in the DNA of the fruit fly.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s also possible to get information about the space usage of a program, but you have to use a version of Perl that was compiled with -DDEBUG, which is not usually the case. If you have such a version, then the following will give you some information:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[tisdall@coltrane]$ perl -DL sizebound.pl
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;But that&amp;rsquo;s enough for here and now; take a look at the Perl documentation section called perldebguts. And drive safely.&lt;/p&gt;

&lt;h3 id=&#34;suggested-reading&#34;&gt;Suggested Reading&lt;/h3&gt;

&lt;p&gt;Here are some of the many books that you might find useful. I cut my teeth on the Bentley books, but the older ones are hard to find.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Introduction to Algorithms, Second Edition, by Cormen et al, MIT Press, 2001.&lt;/li&gt;
&lt;li&gt;Writing Efficient Programs, by Jon Bentley, Prentice Hall 1982.&lt;/li&gt;
&lt;li&gt;Refactoring: Improving the Design of Existing Code, by Fowler et al, Addison-Wesley, 1999.&lt;/li&gt;
&lt;li&gt;Programming Pearls, Second Edition, by Jon Bentley, Prentice Hall 1999.&lt;/li&gt;
&lt;li&gt;More Programming Pearls: Confessions of a Coder, by Jon Bentley, Pearson Education, 1988.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;O&amp;rsquo;Reilly &amp;amp; Associates recently released (September 2003) &lt;a href=&#34;http://www.oreilly.com/catalog/mperlbio/index.html?CMP=IL7015&#34;&gt;Mastering Perl for Bioinformatics&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.oreilly.com/catalog/mperlbio/chapter/index.html?CMP=IL7015&#34;&gt;Sample Chapter 9, Introduction to Bioperl&lt;/a&gt;, is available free online.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;You can also look at the &lt;a href=&#34;http://www.oreilly.com/catalog/mperlbio/toc.html?CMP=IL7015&#34;&gt;Table of Contents&lt;/a&gt;, the &lt;a href=&#34;http://www.oreilly.com/catalog/mperlbio/inx.html?CMP=IL7015&#34;&gt;Index&lt;/a&gt;, and the &lt;a href=&#34;http://www.oreilly.com/catalog/mperlbio/desc.html?CMP=IL7015&#34;&gt;Full Description&lt;/a&gt; of the book.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;For more information, or to order the book, &lt;a href=&#34;http://www.oreilly.com/catalog/mperlbio/index.html?CMP=IL7015&#34;&gt;click here&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>

