<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>S3 on Perl.com - programming news, code and culture</title>
    <link>http://localhost:1313/tags/s3/</link>
    <description>Recent content in S3 on Perl.com - programming news, code and culture</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 11 Jun 2019 00:04:28 +0000</lastBuildDate>
    <atom:link href="/tags/s3/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>What&#39;s new on CPAN - May 2019</title>
      <link>http://localhost:1313/article/what-s-new-on-cpan---may-2019/</link>
      <pubDate>Tue, 11 Jun 2019 00:04:28 +0000</pubDate>
      
      <guid>http://localhost:1313/article/what-s-new-on-cpan---may-2019/</guid>
      <description>

&lt;p&gt;Welcome to &amp;ldquo;What&amp;rsquo;s new on CPAN&amp;rdquo;, a curated look at last month&amp;rsquo;s new CPAN uploads for your reading and programming pleasure. Enjoy!&lt;/p&gt;

&lt;h2 id=&#34;apis&#34;&gt;APIs&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Parse S3 XML responses with &lt;a href=&#34;https://metacpan.org/pod/Amazon::S3::Thin::ResponseParser&#34;&gt;Amazon::S3::Thin::ResponseParser&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Use the Backblaze B2 Cloud Storage Service V2 API via &lt;a href=&#34;https://metacpan.org/pod/Backblaze::B2V2Client&#34;&gt;Backblaze::B2V2Client&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://metacpan.org/pod/GRNOC::WebService::Client&#34;&gt;GRNOC::WebService::Client&lt;/a&gt; provides a client for the Global Research NOC webservice testing utility&lt;/li&gt;
&lt;li&gt;Upload and download files from mediafire.com using &lt;a href=&#34;https://metacpan.org/pod/Mediafire::Api&#34;&gt;Mediafire::Api&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;data&#34;&gt;Data&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://metacpan.org/pod/App::jl&#34;&gt;App::jl&lt;/a&gt; is a recursive JSON decoder&lt;/li&gt;
&lt;li&gt;Use Concise Binary Object Representation in pure Perl with &lt;a href=&#34;https://metacpan.org/pod/CBOR::PP&#34;&gt;CBOR::PP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://metacpan.org/pod/DBIx::Class::ResultDDL&#34;&gt;DBIx::Class::ResultDDL&lt;/a&gt; is another result class declaration simplifier&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://metacpan.org/pod/File::Open::NoCache::ReadOnly&#34;&gt;File::Open::NoCache::ReadOnly&lt;/a&gt; opens files and flushes the cache to minimize memory use&lt;/li&gt;
&lt;li&gt;Get modern XML signature validation with &lt;a href=&#34;https://metacpan.org/pod/XML::Sig::OO&#34;&gt;XML::Sig::OO&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;development-version-control&#34;&gt;Development &amp;amp; Version Control&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://metacpan.org/pod/Code::Style::Kit&#34;&gt;Code::Style::Kit&lt;/a&gt; builds composable bulk exporters&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://metacpan.org/pod/Curio&#34;&gt;Curio&lt;/a&gt; is a &amp;ldquo;Procurer of fine resources and services&amp;rdquo;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://metacpan.org/pod/Data::Dumper::Compact&#34;&gt;Data::Dumper::Compact&lt;/a&gt; dumps vertically compact width-limited data output&lt;/li&gt;
&lt;li&gt;Get an interpreter for spreadsheet-style function expressions, with security in mind &lt;a href=&#34;https://metacpan.org/pod/Language::FormulaEngine&#34;&gt;Language::FormulaEngine&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://metacpan.org/pod/Linux::PacketFilter&#34;&gt;Linux::PacketFilter&lt;/a&gt; is a simple interface to Linux packet filtering&lt;/li&gt;
&lt;li&gt;Track nested timing information using &lt;a href=&#34;https://metacpan.org/pod/Log::Timer&#34;&gt;Log::Timer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://metacpan.org/pod/Test2::Harness::Renderer::JUnit&#34;&gt;Test2::Harness::Renderer::JUnit&lt;/a&gt; captures Test2::Harness results and emits a junit xml file for integration with services like Jenkins&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;web&#34;&gt;Web&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://metacpan.org/pod/Browser::Start&#34;&gt;Browser::Start&lt;/a&gt; opens a URL in a web browser&lt;/li&gt;
&lt;li&gt;Create deep links into mail clients with &lt;a href=&#34;https://metacpan.org/pod/Mail::URLFor&#34;&gt;Mail::URLFor&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://metacpan.org/pod/Mojolicious::Plugin::AutoRoutePm&#34;&gt;Mojolicious::Plugin::AutoRoutePm&lt;/a&gt; automatically adds routes declared in Mojo controllers&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>What&#39;s new on CPAN - November 2017</title>
      <link>http://localhost:1313/article/what-s-new-on-cpan---november-2017/</link>
      <pubDate>Fri, 22 Dec 2017 16:57:02 +0000</pubDate>
      
      <guid>http://localhost:1313/article/what-s-new-on-cpan---november-2017/</guid>
      <description>

&lt;p&gt;Welcome to &amp;ldquo;What&amp;rsquo;s new on CPAN&amp;rdquo;, a curated look at last month&amp;rsquo;s new CPAN uploads for your reading and programming pleasure. Enjoy!&lt;/p&gt;

&lt;h3 id=&#34;apis-apps&#34;&gt;APIs &amp;amp; Apps&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Compute Adler32 digests at the command line with &lt;a href=&#34;https://metacpan.org/pod/App::adler32&#34;&gt;App::adler32&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Get various string escaping/unescaping utilities using &lt;a href=&#34;https://metacpan.org/pod/App::EscapeUtils&#34;&gt;App::EscapeUtils&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;A simple tool for maintaining a shared group secret with &lt;a href=&#34;https://metacpan.org/pod/App::GroupSecret&#34;&gt;App::GroupSecret&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;YouTube has changed their API but you can manage your Watch Later videos with &lt;a href=&#34;https://metacpan.org/pod/App::WatchLater&#34;&gt;App::WatchLater&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://metacpan.org/pod/App::weavedoc&#34;&gt;App::weavedoc&lt;/a&gt; provides a &lt;code&gt;perldoc&lt;/code&gt; for Pod weaver&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://metacpan.org/pod/Net::Async::Beanstalk&#34;&gt;Net::Async::Beanstalk&lt;/a&gt; is a non-blocking beanstalk client&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://metacpan.org/pod/WebService::DeathByCaptcha&#34;&gt;WebService::DeathByCaptcha&lt;/a&gt; provides a Perly interface for the DeathByCaptcha API&lt;/li&gt;
&lt;li&gt;Get a simple mail.ru client with &lt;a href=&#34;https://metacpan.org/pod/Mailru::Cloud&#34;&gt;Mailru::Cloud&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;config-devops&#34;&gt;Config &amp;amp; Devops&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://metacpan.org/pod/File::Globstar&#34;&gt;File::Globstar&lt;/a&gt; provides globstar (**) utils&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://metacpan.org/pod/IPC::Pleather&#34;&gt;IPC::Pleather&lt;/a&gt; - &amp;ldquo;C has Cilk, Perl has Pleather&amp;rdquo;, love it!&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://metacpan.org/pod/Martian&#34;&gt;Martian&lt;/a&gt; extends Starman with max-memory usage cap&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://metacpan.org/pod/MooseX::ConfigCascade&#34;&gt;MooseX::ConfigCascade&lt;/a&gt; is another cascading-style config&lt;/li&gt;
&lt;li&gt;Like Capture::Tiny but with more options, &lt;a href=&#34;https://metacpan.org/pod/POSIX::Run::Capture&#34;&gt;POSIX::Run::Capture&lt;/a&gt; will run a command and capture its output&lt;/li&gt;
&lt;li&gt;Identify Perl releases and download the most recent via FTP using &lt;a href=&#34;https://metacpan.org/pod/Perl::Download::FTP&#34;&gt;Perl::Download::FTP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Parse files with continuation lines with &lt;a href=&#34;https://metacpan.org/pod/Text::Continuation::Parser&#34;&gt;Text::Continuation::Parser&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Pack your Perl applications for Windows with &lt;a href=&#34;https://metacpan.org/pod/Win32::Packer&#34;&gt;Win32::Packer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://metacpan.org/pod/Win32::Shortkeys::Kbh&#34;&gt;Win32::Shortkeys::Kbh&lt;/a&gt; is a module for hooking the keyboard on Windows&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;data&#34;&gt;Data&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://metacpan.org/pod/Data::Pokemon::Go&#34;&gt;Data::Pokemon::Go&lt;/a&gt; aims to provide data for every Pokemon in Pokemon Go, the author is calling for contributors&lt;/li&gt;
&lt;li&gt;Represent a financial asset with &lt;a href=&#34;https://metacpan.org/pod/Finance::Underlying&#34;&gt;Finance::Underlying&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://metacpan.org/pod/IO::ReadHandle::Chain&#34;&gt;IO::ReadHandle::Chain&lt;/a&gt; can conveniently chain IO of multiple sources through a single filehandle&lt;/li&gt;
&lt;li&gt;Find the size of JPEG images with &lt;a href=&#34;https://metacpan.org/pod/Image::JPEG::Size&#34;&gt;Image::JPEG::Size&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Translate the latest JSON-Schema (v06) into Perl code using &lt;a href=&#34;https://metacpan.org/pod/JSV::Compiler&#34;&gt;JSV::Compiler&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Manipulate LRC karaoke timed lyrics files using &lt;a href=&#34;https://metacpan.org/pod/Music::Lyrics::LRC&#34;&gt;Music::Lyrics::LRC&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Read &lt;code&gt;.slob&lt;/code&gt; dictionaries (for Aard 2) using &lt;a href=&#34;https://metacpan.org/pod/Slob&#34;&gt;Slob&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Generate XML from simple Perl data structures with &lt;a href=&#34;https://metacpan.org/pod/XML::FromPerl&#34;&gt;XML::FromPerl&lt;/a&gt; - sounds a lot like XML::Simple, but uses libxml2&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;development-version-control&#34;&gt;Development &amp;amp; Version Control&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Asynchronously run code concurrently in a pool of perl processes using &lt;a href=&#34;https://metacpan.org/pod/AnyEvent::ProcessPool&#34;&gt;AnyEvent::ProcessPool&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Get a useful counter that signals when it reaches 0 with &lt;a href=&#34;https://metacpan.org/pod/Coro::Countdown&#34;&gt;Coro::Countdown&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://metacpan.org/pod/Doit&#34;&gt;Doit&lt;/a&gt; is a framework for Perl scripting&lt;/li&gt;
&lt;li&gt;Moose has it&amp;rsquo;s clones, and now Mojo::Base has &lt;a href=&#34;https://metacpan.org/pod/Jojo::Base&#34;&gt;Jojo::Base&lt;/a&gt;, which implements a lexical &lt;code&gt;has&lt;/code&gt;. Naturally there is &lt;a href=&#34;https://metacpan.org/pod/Jojo::Role&#34;&gt;Jojo::Role&lt;/a&gt; too&lt;/li&gt;
&lt;li&gt;Create Moo classes with IO::Async event handlers using &lt;a href=&#34;https://metacpan.org/pod/MooX::EventHandler&#34;&gt;MooX::EventHandler&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://metacpan.org/pod/Sort::Naturally::ICU&#34;&gt;Sort::Naturally::ICU&lt;/a&gt; implements a fast, natural sort&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;other&#34;&gt;Other&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Generate AWS S3 signed URLs using the aptly-named &lt;a href=&#34;https://metacpan.org/pod/Amazon::S3::SignedURLGenerator&#34;&gt;Amazon::S3::SignedURLGenerator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://metacpan.org/pod/Authen::Krb5&#34;&gt;Authen::Krb5&lt;/a&gt; provides XS bindings for Kerberos 5, the secure network protocol&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://metacpan.org/pod/Neovim::RPC::Plugin::Taskwarrior&#34;&gt;Neovim::RPC::Plugin::Taskwarrior&lt;/a&gt; provides a Neovim UI for taskwarrior&lt;/li&gt;
&lt;li&gt;Get &lt;code&gt;printf&lt;/code&gt; style functions that handle multibyte characters using &lt;a href=&#34;https://metacpan.org/pod/Text::VisualPrintf&#34;&gt;Text::VisualPrintf&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;science-mathematics&#34;&gt;Science &amp;amp; Mathematics&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Use the Boutros Lab valection C library from Perl with &lt;a href=&#34;https://metacpan.org/pod/Bio::Sampling::Valection&#34;&gt;Bio::Sampling::Valection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Track events and calculate a rolling average of time &lt;a href=&#34;https://metacpan.org/pod/Time::Spent&#34;&gt;Time::Spent&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;testing&#34;&gt;Testing&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Test if a cpanfile lists every used module with &lt;a href=&#34;https://metacpan.org/pod/Test::CPANfile&#34;&gt;Test::CPANfile&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://metacpan.org/pod/Test::Class::WithStrictPlan&#34;&gt;Test::Class::WithStrictPlan&lt;/a&gt; makes sure Test::Class executes the declared number of tests&lt;/li&gt;
&lt;li&gt;Declare subtests using subroutine attributes with &lt;a href=&#34;https://metacpan.org/pod/Test::Subtest::Attribute&#34;&gt;Test::Subtest::Attribute&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Test that your XS files are problem-free with XS::Check with &lt;a href=&#34;https://metacpan.org/pod/Test::XS::Check&#34;&gt;Test::XS::Check&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://metacpan.org/pod/Test::HTML::Recursive::DeprecatedTags&#34;&gt;Test::HTML::Recursive::DeprecatedTags&lt;/a&gt; can check HTML files for deprecated tags&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;web&#34;&gt;Web&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Generate pretty HTML from Perl code in a Dancer2 app using &lt;a href=&#34;https://metacpan.org/pod/Dancer2::Plugin::SyntaxHighlight::Perl&#34;&gt;Dancer2::Plugin::SyntaxHighlight::Perl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://metacpan.org/pod/Ion&#34;&gt;Ion&lt;/a&gt; aims to be a &amp;ldquo;clear and concise API for writing TCP servers and clients&amp;rdquo;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://metacpan.org/pod/Mojo::Collection::Role::UtilsBy&#34;&gt;Mojo::Collection::Role::UtilsBy&lt;/a&gt; provides List::UtilsBy methods for Mojo::Collection objects&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>AWS Cloudfront cache invalidation with Paws</title>
      <link>http://localhost:1313/article/aws-cloudfront-cache-invalidation-with-paws/</link>
      <pubDate>Mon, 03 Apr 2017 08:12:14 +0000</pubDate>
      
      <guid>http://localhost:1313/article/aws-cloudfront-cache-invalidation-with-paws/</guid>
      <description>

&lt;p&gt;In &lt;a href=&#34;http://localhost:1313/article/deploy-a-static-website-with-aws-s3-and-paws/&#34;&gt;Deploy a static website with Paws&lt;/a&gt;, I developed a simple script to upload files to AWS S3, using &lt;a href=&#34;https://metacpan.org/pod/Paws&#34;&gt;Paws&lt;/a&gt;. In this article I&amp;rsquo;ll describe a script to invalidate CloudFront caches: this can be used to force CloudFront to re-cache files which have changed on S3.&lt;/p&gt;

&lt;h3 id=&#34;aws-cloudfront&#34;&gt;AWS CloudFront&lt;/h3&gt;

&lt;p&gt;CloudFront is Amazon&amp;rsquo;s Content Delivery Network service. It&amp;rsquo;s used to cache local versions of files so that they can be delivered to requests faster; for example if you used S3 to host your website in Amazon&amp;rsquo;s US East region, files on the website might load faster for East Coast customers than those on the West Coast. With a CDN like CloudFront however, copies of the website files can be saved all over the World, so that visitor&amp;rsquo;s browsers fetch the website files from closer geographic locations, improving the website speed.&lt;/p&gt;

&lt;p&gt;When cached website files are updated on S3, they need to be invalidated from the CloudFront cache. This forces CloudFront to fetch fresh copies of invalidated files.&lt;/p&gt;

&lt;h3 id=&#34;the-code&#34;&gt;The code&lt;/h3&gt;

&lt;p&gt;Using CloudFront with Paws is pretty easy. For cache invalidation all you really need is a CloudFront distribution id, and a list of files to be invalidated. This is the script:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-perl&#34; data-lang=&#34;perl&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#!/usr/bin/env perl&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;use&lt;/span&gt; strict;
&lt;span style=&#34;color:#66d9ef&#34;&gt;use&lt;/span&gt; warnings;
&lt;span style=&#34;color:#66d9ef&#34;&gt;use&lt;/span&gt; Paws;
&lt;span style=&#34;color:#66d9ef&#34;&gt;use&lt;/span&gt; Getopt::Long &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;GetOptions&amp;#39;&lt;/span&gt;;
&lt;span style=&#34;color:#66d9ef&#34;&gt;use&lt;/span&gt; Time::HiRes &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gettimeofday&amp;#39;&lt;/span&gt;;

GetOptions(
  &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;distribution-id=s&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;\&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;my&lt;/span&gt; $DISTRIBUTION_ID,
  &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;keys=s&amp;#39;&lt;/span&gt;            &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;\&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;my&lt;/span&gt; @KEYS,
  &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;region=s&amp;#39;&lt;/span&gt;          &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;\&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;my&lt;/span&gt; $REGION,
) &lt;span style=&#34;color:#f92672&#34;&gt;or&lt;/span&gt; die &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;unrecognized arguments&amp;#39;&lt;/span&gt;;

die &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;--distribution-id and --region are required&amp;#39;&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;unless&lt;/span&gt; $DISTRIBUTION_ID &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; $REGION;

&lt;span style=&#34;color:#75715e&#34;&gt;# don&amp;#39;t block on empty STDIN&lt;/span&gt;
STDIN&lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;blocking(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;);
@KEYS &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; map { chomp;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/$_&amp;#34;&lt;/span&gt; } @KEYS, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;lt;STDIN&amp;gt;&lt;/span&gt;;
die &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;no objects to invalidate!&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;unless&lt;/span&gt; @KEYS;
printf &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Invalidating cached keys: %s\n&amp;#34;&lt;/span&gt;, join &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;, &amp;#39;&lt;/span&gt;, @KEYS;

&lt;span style=&#34;color:#66d9ef&#34;&gt;my&lt;/span&gt; $cfront &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Paws&lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;service(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;CloudFront&amp;#39;&lt;/span&gt;, region &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; $REGION);
&lt;span style=&#34;color:#66d9ef&#34;&gt;my&lt;/span&gt; $uid    &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; join &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;-&amp;#39;&lt;/span&gt;, gettimeofday();

$cfront&lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;CreateInvalidation(
  DistributionId    &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; $DISTRIBUTION_ID,
  InvalidationBatch &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; {
      CallerReference &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; $uid,
      Paths           &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; {
        Quantity &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; scalar @KEYS,
        Items    &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;\&lt;/span&gt;@KEYS,
      }
  }
);&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As before, I use &lt;a href=&#34;https://metacpan.org/pod/Getopt::Long&#34;&gt;Getopt::Long&lt;/a&gt; to process the command line options. The script requires a CloudFront distribution id and an AWS region string. The &lt;code&gt;--keys&lt;/code&gt; switch is optional as the script also reads keys from &lt;code&gt;STDIN&lt;/code&gt;. This snippet is curious:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-perl&#34; data-lang=&#34;perl&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# don&amp;#39;t block on empty STDIN&lt;/span&gt;
STDIN&lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;blocking(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;);
@KEYS &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; map { chomp;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/$_&amp;#34;&lt;/span&gt; } @KEYS, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;lt;STDIN&amp;gt;&lt;/span&gt;;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It sets the &lt;code&gt;STDIN&lt;/code&gt; filehandle to non-blocking mode. That way, if STDIN is empty when the script tries to read from it, it won&amp;rsquo;t block. On the next line, &lt;code&gt;map&lt;/code&gt; is used to prepend a slash to every key. This is required by CloudFront.&lt;/p&gt;

&lt;p&gt;The script then creates a Paws CloudFront object, and the &lt;a href=&#34;https://metacpan.org/pod/Time::HiRes&#34;&gt;Time::HiRes&lt;/a&gt; &lt;code&gt;gettimeofday&lt;/code&gt; function is used to calculate a cheap unique id (it returns the current epoch seconds and microseconds).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-perl&#34; data-lang=&#34;perl&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;my&lt;/span&gt; $cfront &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Paws&lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;service(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;CloudFront&amp;#39;&lt;/span&gt;, region &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; $REGION);
&lt;span style=&#34;color:#66d9ef&#34;&gt;my&lt;/span&gt; $uid    &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; join &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;-&amp;#39;&lt;/span&gt;, gettimeofday();&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally, the script calls the &lt;code&gt;CreateInvalidation&lt;/code&gt; method to send the data to AWS CloudFront:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-perl&#34; data-lang=&#34;perl&#34;&gt;$cfront&lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;CreateInvalidation(
  DistributionId    &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; $DISTRIBUTION_ID,
  InvalidationBatch &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; {
      CallerReference &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; $uid,
      Paths           &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; {
        Quantity &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; scalar @KEYS,
        Items    &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;\&lt;/span&gt;@KEYS,
      }
  }
);&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id=&#34;combining-tools&#34;&gt;Combining tools&lt;/h3&gt;

&lt;p&gt;The &lt;code&gt;s3-upload&lt;/code&gt; script prints the keys it updated on STDOUT, and &lt;code&gt;cf-invalid&lt;/code&gt; can read keys from STDIN. This makes for convenient chaining:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;./s3-upload --files static --bucket example.com --region us-east-1 \
| ./cf-invalid --distribution-id e9d4922bd9120 --region us-east-1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And because the scripts use &lt;a href=&#34;https://metacpan.org/pod/Getopt::Long&#34;&gt;Getopt::Long&lt;/a&gt;, the option names can be shortened:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;./s3-upload -f static -b example.com -r us-east-1 | ./cf-invalid -d e9d4922bd9120 -r us-east-1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Alternatively, keys (filenames) can be specified as arguments:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;./cf-invalid -d e9d4922bd9120 -r us-east-1 -k index.html -k about.html -k contact.html
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Both scripts are available on &lt;a href=&#34;https://github.com/dnmfarrell/Paws-tools&#34;&gt;Github&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;em&gt;This article was originally posted on &lt;a href=&#34;http://perltricks.com&#34;&gt;PerlTricks.com&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deploy a static website with AWS S3 and Paws</title>
      <link>http://localhost:1313/article/deploy-a-static-website-with-aws-s3-and-paws/</link>
      <pubDate>Tue, 21 Feb 2017 10:04:00 +0000</pubDate>
      
      <guid>http://localhost:1313/article/deploy-a-static-website-with-aws-s3-and-paws/</guid>
      <description>

&lt;p&gt;Amazon Web Services (AWS) is Amazon&amp;rsquo;s cloud services platform and S3 is the AWS file storage service. S3 is commonly used to host static websites. With Perl we have many modules for using AWS, but I like &lt;a href=&#34;https://metacpan.org/pod/Paws&#34;&gt;Paws&lt;/a&gt;, developed by &lt;a href=&#34;https://metacpan.org/author/JLMARTIN&#34;&gt;Jose Luis Martinez&lt;/a&gt; which supports many AWS services, including S3. In this article I&amp;rsquo;ll walk you through a Perl script I developed to upload and maintain a static website using S3 and Paws.&lt;/p&gt;

&lt;h3 id=&#34;aws-setup&#34;&gt;AWS setup&lt;/h3&gt;

&lt;p&gt;To use AWS from the command line you&amp;rsquo;ll need a to generate a key id and secret key for your account which you can get from the &lt;a href=&#34;https://aws.amazon.com/&#34;&gt;AWS website&lt;/a&gt;. Once you login with your Amazon credentials, click on your account name and go to &amp;ldquo;My Security Credentials&amp;rdquo;. Once you have a key id and secret key, you need to create the credentials files as used by &lt;a href=&#34;http://docs.aws.amazon.com/cli/latest/userguide/cli-chap-getting-started.html&#34;&gt;awscli&lt;/a&gt;. You can either install awscli and run &lt;code&gt;aws configure&lt;/code&gt;, else create:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;~/.aws/default:
[default]
output = JSON
region = us-east

~/.aws/config:
[default]
aws_access_key_id = XXXXXXXXXXXX
aws_secret_access_key = xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Change the region value to the &lt;a href=&#34;http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.RegionsAndAvailabilityZones.html&#34;&gt;AWS region&lt;/a&gt; you want to use, and replace the &amp;ldquo;XXX&amp;rdquo; values with your own key id and secret key values. These files are stored in a different &lt;a href=&#34;http://docs.aws.amazon.com/cli/latest/userguide/cli-chap-getting-started.html#config-settings-and-precedence&#34;&gt;location&lt;/a&gt; on Windows.&lt;/p&gt;

&lt;h3 id=&#34;create-an-s3-bucket&#34;&gt;Create an S3 bucket&lt;/h3&gt;

&lt;p&gt;S3 organizes files by bucket. Every bucket has URI-like name, which is unique across AWS. So if you&amp;rsquo;re going to host a website on S3, you&amp;rsquo;ll need to create a bucket for the website. This can be done via the AWS &lt;a href=&#34;https://aws.amazon.com/&#34;&gt;web interface&lt;/a&gt;, the command-line &lt;a href=&#34;http://docs.aws.amazon.com/cli/latest/reference/s3/mb.html&#34;&gt;app&lt;/a&gt; or with Paws:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-perl&#34; data-lang=&#34;perl&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;use&lt;/span&gt; Paws;
&lt;span style=&#34;color:#66d9ef&#34;&gt;my&lt;/span&gt; $s3 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Paws&lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;service(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;S3&amp;#39;&lt;/span&gt;, region &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;us-east-1&amp;#39;&lt;/span&gt;);
$s3&lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;CreateBucket(Bucket &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mystaticwebsite.com&amp;#39;&lt;/span&gt;, ACL &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;public-read&amp;#39;&lt;/span&gt;);&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The &lt;code&gt;ACL&lt;/code&gt; argument specifies that the bucket can be read publicly, but not edited, which makes sense for website files. At some point, you&amp;rsquo;ll need to enable the &amp;ldquo;static web hosting&amp;rdquo; &lt;a href=&#34;https://console.aws.amazon.com/s3/buckets/&#34;&gt;option&lt;/a&gt; for the bucket, but that&amp;rsquo;s not necessary to upload files to it.&lt;/p&gt;

&lt;h3 id=&#34;upload-files-to-s3&#34;&gt;Upload files to S3&lt;/h3&gt;

&lt;p&gt;S3 files are stored as objects in buckets. Every file has a key, which is similar to the filename. I&amp;rsquo;ve developed a &lt;a href=&#34;https://github.com/dnmfarrell/Paws-tools/blob/master/s3-upload&#34;&gt;script&lt;/a&gt; called &lt;code&gt;s3-upload&lt;/code&gt; which uses Paws to upload files to S3 buckets. It uses &lt;a href=&#34;https://metacpan.org/pod/Getopt::Long&#34;&gt;Getopt::Long&lt;/a&gt; to parse command line options. It requires &lt;code&gt;--bucket&lt;/code&gt; for the S3 bucket name, &lt;code&gt;--region&lt;/code&gt; for the AWS region, and &lt;code&gt;--files&lt;/code&gt; for the directory filepath:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-perl&#34; data-lang=&#34;perl&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#!/usr/bin/env perl&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;use&lt;/span&gt; Getopt::Long &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;GetOptions&amp;#39;&lt;/span&gt;;
&lt;span style=&#34;color:#66d9ef&#34;&gt;use&lt;/span&gt; Paws;
&lt;span style=&#34;color:#66d9ef&#34;&gt;use&lt;/span&gt; Path::Tiny &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;path&amp;#39;&lt;/span&gt;;

GetOptions(
  &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;bucket=s&amp;#39;&lt;/span&gt;     &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;\&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;my&lt;/span&gt; $BUCKET,
  &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;files=s&amp;#39;&lt;/span&gt;      &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;\&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;my&lt;/span&gt; $BASEPATH,
  &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;region=s&amp;#39;&lt;/span&gt;     &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;\&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;my&lt;/span&gt; $REGION,
  &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;delete-stale&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;\&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;my&lt;/span&gt; $DELETE_STALE,
) &lt;span style=&#34;color:#f92672&#34;&gt;or&lt;/span&gt; die &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;unrecognized arguments&amp;#39;&lt;/span&gt;;

die &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;must provide --bucket --region --files&amp;#39;&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;unless&lt;/span&gt; $BUCKET &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; $REGION &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; $BASEPATH;

die &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;directory $BASEPATH not found&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;unless&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;d $BASEPATH;

&lt;span style=&#34;color:#66d9ef&#34;&gt;my&lt;/span&gt; $s3             &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Paws&lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;service(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;S3&amp;#39;&lt;/span&gt;, region &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; $REGION);
&lt;span style=&#34;color:#66d9ef&#34;&gt;my&lt;/span&gt; $remote_objects &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; get_remote_objects($s3);
&lt;span style=&#34;color:#66d9ef&#34;&gt;my&lt;/span&gt; $local_objects  &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; upload($s3, $remote_objects);

delete_stale_objects($s3, $remote_objects, $local_objects) &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; $DELETE_STALE;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I&amp;rsquo;ve omitted the subroutine definitions for brevity (see the &lt;a href=&#34;https://github.com/dnmfarrell/Paws-tools/blob/master/s3-upload&#34;&gt;source&lt;/a&gt; for details). The script begins by validating the input options, then creates an &lt;code&gt;$s3&lt;/code&gt; object. It calls &lt;code&gt;get_remote_objects&lt;/code&gt; which returns a hashref of keys (files) and their last modified time currently in the bucket. It passes this to &lt;code&gt;upload&lt;/code&gt; which only uploads files that have been modified since being uploaded to S3 (you don&amp;rsquo;t want to upload the entire website if only one file has changed). &lt;code&gt;upload&lt;/code&gt; does many things, but essentially, it uses &lt;a href=&#34;https://metacpan.org/pod/Paws::S3::PutObject&#34;&gt;PutObject&lt;/a&gt; to upload files:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-perl&#34; data-lang=&#34;perl&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;sub&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;upload&lt;/span&gt; {
  &lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;
  $s3&lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;PutObject(
    Bucket  &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; $BUCKET,
    Key     &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; $key,
    ACL     &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;public-read&amp;#39;&lt;/span&gt;,
    Body    &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; $path&lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;slurp_raw,
  );
  &lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Here &lt;code&gt;Key&lt;/code&gt; is the filename and &lt;code&gt;Body&lt;/code&gt; the raw bytes of the file. The &lt;code&gt;upload&lt;/code&gt; subroutine also returns a hashref of local keys and their last modified time. Optionally, the script can call &lt;code&gt;delete_stale_objects&lt;/code&gt; which deletes files from S3 which do not exist in the local tree.&lt;/p&gt;

&lt;p&gt;The script can be run like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ./s3-upload --bucket mystaticwebsite.com --region us-east-1 --files mywebsite/static --delete-stale
static/index.html
static/about.html
static/news.html
static/products.html
static/css/styles.css
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The script will print any files uploaded to STDOUT and all other output to STDERR. The intention is to make it possible to pipe the filenames uploaded to other programs. A useful one might be a Cloudfront script which invalidates the cache for any files uploaded.&lt;/p&gt;

&lt;h3 id=&#34;more-features&#34;&gt;More features&lt;/h3&gt;

&lt;p&gt;Whilst the above script does the job, there are some features missing that are useful for static websites. Firstly, you might want to specify the MIME type of the files being uploaded. This is so when browsers fetch the files, S3 responds with the correct content type &lt;a href=&#34;https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Type&#34;&gt;header&lt;/a&gt;. Otherwise, HTML files may not be displayed as websites, images may be downloaded instead of displayed, and so on. I use &lt;a href=&#34;https://metacpan.org/pod/Media::Type::Simple&#34;&gt;Media::Type::Simple&lt;/a&gt; for this:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-perl&#34; data-lang=&#34;perl&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;use&lt;/span&gt; Media::Type::Simple;
&lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# setup mime types, add missing&lt;/span&gt;
open &lt;span style=&#34;color:#66d9ef&#34;&gt;my&lt;/span&gt; $mime_types, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;lt;&amp;#39;&lt;/span&gt;, $MIME_TYPES &lt;span style=&#34;color:#f92672&#34;&gt;or&lt;/span&gt; die &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Can&amp;#39;t find $MIME_TYPES $!&amp;#34;&lt;/span&gt;;
&lt;span style=&#34;color:#66d9ef&#34;&gt;my&lt;/span&gt; $media &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Media::Type::Simple&lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;new&lt;/span&gt;($mime_types);
$media&lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;add_type(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;application/font-woff2&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;woff2&amp;#39;&lt;/span&gt;);
&lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;my&lt;/span&gt; @ext  &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; $path &lt;span style=&#34;color:#f92672&#34;&gt;=~&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;/\.(\w+)$/&lt;/span&gt;;
&lt;span style=&#34;color:#66d9ef&#34;&gt;my&lt;/span&gt; $mime &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; eval { @ext ? $media&lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;type_from_ext($ext[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]) : undef };
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; STDERR $@ &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; $@;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I&amp;rsquo;ve uploaded a copy of &lt;code&gt;mime.types&lt;/code&gt; to the &lt;a href=&#34;https://github.com/dnmfarrell/Paws-tools/blob/master/mime.types&#34;&gt;repo&lt;/a&gt;, and added a &lt;code&gt;--mime-types&lt;/code&gt; option for the filepath to a mime.types file (defaulting to &lt;code&gt;/etc/mime.types&lt;/code&gt;). Also not all media types are defined, so the code adds a custom definition for &lt;code&gt;woff2&lt;/code&gt;. The mime type is passed to &lt;code&gt;PutObject&lt;/code&gt; when a file is uploaded.&lt;/p&gt;

&lt;p&gt;Other useful options supported by the script:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--strip&lt;/code&gt;- it seems cleaner to visit: &lt;code&gt;/home&lt;/code&gt; than &lt;code&gt;/home.html&lt;/code&gt;. The &lt;code&gt;--strip&lt;/code&gt; option can be used to specify any extensions to strip from filenames&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--max-age&lt;/code&gt; - set a cache control header to have browsers cache files instead of downloading them on every page&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--force&lt;/code&gt; - override the default behavior and upload all files, regardless of whether they already exist in the S3 bucket&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These options can be used like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ./s3-upload --bucket mystaticwebsite.com --region us-east-1 --files mywebsite/static --delete-stale --mime-types mime.types --strip html --max-age 31536000 --force
static/index.html
static/about.html
static/news.html
static/products.html
static/css/styles.css
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The script &lt;a href=&#34;https://github.com/dnmfarrell/Paws-tools/blob/master/s3-upload&#34;&gt;source&lt;/a&gt; is on GitHub. If you need help configuring a static website for AWS, Amazon have provided a good &lt;a href=&#34;http://docs.aws.amazon.com/gettingstarted/latest/swh/website-hosting-intro.html&#34;&gt;guide&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;em&gt;This article was originally posted on &lt;a href=&#34;http://perltricks.com&#34;&gt;PerlTricks.com&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Using Amazon S3 from Perl</title>
      <link>http://localhost:1313/pub/2008/04/08/using-amazon-s3-from-perl.html/</link>
      <pubDate>Tue, 08 Apr 2008 00:00:00 -0800</pubDate>
      
      <guid>http://localhost:1313/pub/2008/04/08/using-amazon-s3-from-perl.html/</guid>
      <description>

&lt;p&gt;Data management is a critical and challenging aspect for any online resource. With exponentially growing data sizes and popularity of rich media, even small online resources must effectively manage and distribute a significant amount of data. Moreover, the peace of mind associated with an additional offsite data storage resource is invaluable to everyone involved.&lt;/p&gt;

&lt;p&gt;At &lt;a href=&#34;http://www.sundaymorningrides.com/&#34;&gt;SundayMorningRides.com&lt;/a&gt;, we manage a growing inventory of GPS and general GIS (Geography Information Systems) data and web content (text, images, videos, etc.) for the end users. In addition, we must also effectively manage daily snapshots, backups, as well as multiple development versions of our web site and supporting software. For any small organization, this can add up to significant costs &amp;ndash; not only as an initial monetary investment but also in terms of ongoing labor costs for maintenance and administration.&lt;/p&gt;

&lt;p&gt;Amazon Simple Storage Service (S3) was released specifically to address the problem of data management for online resources &amp;ndash; with the aim to provide &amp;ldquo;reliable, fast, inexpensive data storage infrastructure that Amazon uses to run its own global network of web sites.&amp;rdquo; Amazon S3 provides a web service interface that allows developers to store and retrieve any amount of data. S3 is attractive to companies like SundayMorningRides.com as it frees us from upfront costs and the ongoing costs of purchasing, administration, maintenance, and scaling our own storage servers.&lt;/p&gt;

&lt;p&gt;This article covers the Perl, REST, and the Amazon S3 REST module, walking through the development of a collection of Perl-based tools for UNIX command-line based interaction to Amazon S3. I&amp;rsquo;ll also show how to set access permissions so that you can serve images or other data directly to your site from Amazon S3.&lt;/p&gt;

&lt;h4 id=&#34;a-bit-on-web-services&#34;&gt;A Bit on Web Services&lt;/h4&gt;

&lt;p&gt;Web services have become the de-facto method of exposing information and, well, services via the Web. Intrinsically, web services provide a means of interaction between two networked resources. Amazon S3 is accessible via both Simple Object Access Protocol (SOAP) or representational state transfer (REST).&lt;/p&gt;

&lt;p&gt;The SOAP interface organizes features into custom-built operations, similar to remote objects when using Java Remote Method Invocation (RMI) or Common Object Resource Broker Architecture (CORBA). Unlike RMI or CORBA, SOAP uses XML embedded in the body of HTTP requests as the application protocol.&lt;/p&gt;

&lt;p&gt;Like SOAP, REST also uses HTTP for transport. Unlike SOAP, REST operations are the standard HTTP operations &amp;ndash; GET, POST, PUT, and DELETE. I think of REST operations in terms of the CRUD semantics associated with relational databases: POST is Create, GET is Retrieve, PUT is Update, and DELETE is Delete.&lt;/p&gt;

&lt;h4 id=&#34;storage-for-the-internet&#34;&gt;&amp;ldquo;Storage for the Internet&amp;rdquo;&lt;/h4&gt;

&lt;p&gt;Amazon S3 represents the data space in three core concepts: &lt;em&gt;objects&lt;/em&gt;, &lt;em&gt;buckets&lt;/em&gt;, and &lt;em&gt;keys&lt;/em&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Objects are the base level entities within Amazon S3. They consist of both object data and metadata. This metadata is a set of name-attribute pairs defined in the HTTP header.&lt;/li&gt;
&lt;li&gt;Buckets are collections of objects. There is no limit to the number of objects in a bucket, but each developer is limited to 100 buckets.&lt;/li&gt;
&lt;li&gt;Keys are unique identifiers for objects.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Without wading through the details, I tend think of buckets as folders, objects as files, and keys as filenames. The purpose of this abstraction is to create a unique HTTP namespace for every object.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ll assume that you have already signed up for &lt;a href=&#34;http://aws.amazon.com/s3&#34;&gt;Amazon S3&lt;/a&gt; and received your Access Key ID and Secret Access Key. If not, please do so.&lt;/p&gt;

&lt;p&gt;Please note that the &lt;code&gt;S3::*&lt;/code&gt; modules aren&amp;rsquo;t the only Perl modules available for connecting to Amazon S3. In particular, &lt;a href=&#34;https://metacpan.org/pod/Net::Amazon::S3&#34;&gt;Net::Amazon::S3&lt;/a&gt; hides a lot of the details of the S3 service for you. For now, I&amp;rsquo;m going to use a simpler module to explain how the service works internally.&lt;/p&gt;

&lt;h4 id=&#34;connecting-creating-and-listing-buckets&#34;&gt;Connecting, Creating, and Listing Buckets&lt;/h4&gt;

&lt;p&gt;Connecting to Amazon S3 is as simple as supplying your Access Key ID and your Secret Access Key to create a connection, called here &lt;code&gt;$conn&lt;/code&gt;. Here&amp;rsquo;s how to create and list the contents of a bucket as well as list all buckets.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#!/usr/bin/perl

use S3::AWSAuthConnection;
use S3::QueryStringAuthGenerator;

use Data::Dumper;

my $AWS_ACCESS_KEY_ID     = &#39;YOUR ACCESS KEY&#39;;
my $AWS_SECRET_ACCESS_KEY = &#39;YOUR SECRET KEY&#39;;

my $conn = S3::AWSAuthConnection-&amp;gt;new($AWS_ACCESS_KEY_ID,
                                      $AWS_SECRET_ACCESS_KEY);

my $BUCKET = &amp;quot;foo&amp;quot;;

print &amp;quot;creating bucket $BUCKET \n&amp;quot;;
print $conn-&amp;gt;create_bucket($BUCKET)-&amp;gt;message, &amp;quot;\n&amp;quot;;

print &amp;quot;listing bucket $BUCKET \n&amp;quot;;
print Dumper @{$conn-&amp;gt;list_bucket($BUCKET)-&amp;gt;entries}, &amp;quot;\n&amp;quot;;

print &amp;quot;listing all my buckets \n&amp;quot;;
print Dumper @{$conn-&amp;gt;list_all_my_buckets()-&amp;gt;entries}, &amp;quot;\n&amp;quot;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Because every S3 action takes place over HTTP, it is good practice to check for a 200 response.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;my $response = $conn-&amp;gt;create_bucket($BUCKET);
if ($response-&amp;gt;http_response-&amp;gt;code == 200) {
    # Good
} else {
    # Not Good
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As you can see from the output, the results come back in a hash. I&amp;rsquo;ve used &lt;a href=&#34;https://metacpan.org/pod/Data::Dumper&#34;&gt;Data::Dumper&lt;/a&gt; as a convenient way to view the contents. If you are running this for the first time, you will obviously not see anything listed in the bucket.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;listing bucket foo
$VAR1 = {
          &#39;Owner&#39; =&amp;gt; {
                     &#39;ID&#39; =&amp;gt; &#39;xxxxx&#39;,
                     &#39;DisplayName&#39; =&amp;gt; &#39;xxxxx&#39;
                   },
          &#39;Size&#39; =&amp;gt; &#39;66810&#39;,
          &#39;ETag&#39; =&amp;gt; &#39;&amp;quot;xxxxx&amp;quot;&#39;,
          &#39;StorageClass&#39; =&amp;gt; &#39;STANDARD&#39;,
          &#39;Key&#39; =&amp;gt; &#39;key&#39;,
          &#39;LastModified&#39; =&amp;gt; &#39;2007-12-18T22:08:09.000Z&#39;
        };
$VAR4 = &#39;
&#39;;
listing all my buckets
$VAR1 = {
          &#39;CreationDate&#39; =&amp;gt; &#39;2007-11-28T17:31:48.000Z&#39;,
          &#39;Name&#39; =&amp;gt; &#39;foo&#39;
        };
&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;writing-an-object&#34;&gt;Writing an Object&lt;/h4&gt;

&lt;p&gt;Writing an object is simply a matter of using the HTTP PUT method. Be aware that there is nothing to prevent you from overwriting an existing object; Amazon S3 will automatically update the object with the more recent write request. Also, it&amp;rsquo;s currently not possible to append to or otherwise modify an object in place without replacing it.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;my %headers = (
    &#39;Content-Type&#39; =&amp;gt; &#39;text/plain&#39;
);
$response = $conn-&amp;gt;put( $BUCKET, $KEY, S3Object-&amp;gt;new(&amp;quot;this is a test&amp;quot;),
                        \%headers);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Likewise, you can read a file from STDIN:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;my %headers;

FILE: while(1) {
    my $n = sysread(STDIN, $data, 1024 * 1024, length($data));
    if ($n &amp;lt; 0) {
        print STDERR &amp;quot;Error reading input: $!\n&amp;quot;;
        exit 1;
    }
    last FILE if $n == 0;
}
$response = $conn-&amp;gt;put(&amp;quot;$BUCKET&amp;quot;, &amp;quot;$KEY&amp;quot;, $data, \%headers);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To add custom metadata, simply add to the &lt;code&gt;S3Object&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;S3Object-&amp;gt;new(&amp;quot;this is a test&amp;quot;, { name =&amp;gt; &amp;quot;attribute&amp;quot; })
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;By default, every object has private access control when written. This allows only the user that stored the object to read it back. You can change these settings. Also, note that each object can hold a maximum of 5 GB of data.&lt;/p&gt;

&lt;p&gt;You are probably wondering if it is also possible to upload via a standard HTTP POST. The folks at Amazon are working on it as we speak &amp;ndash; see &lt;a href=&#34;http://developer.amazonwebservices.com/connect/thread.jspa?threadID=18616&amp;amp;tstart=0&#34;&gt;HTTP POST beta discussion&lt;/a&gt; for more information. Until that&amp;rsquo;s finished, you&amp;rsquo;ll have to perform web-based uploads via an intermediate server.&lt;/p&gt;

&lt;h4 id=&#34;reading-an-object&#34;&gt;Reading an Object&lt;/h4&gt;

&lt;p&gt;Like writing objects, there are several ways to read data from Amazon S3. One way is to generate a temporary URL to use with your favorite client (for example, wget or Curl) or even a browser to view or retrieve the object. All you have to do is generate the URL used to make the REST call.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;my $generator = S3::QueryStringAuthGenerator-&amp;gt;new($AWS_ACCESS_KEY_ID,
    $AWS_SECRET_ACCESS_KEY);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;hellip;and then perform a simple HTTP GET request. This is a great trick if all you want to do is temporarily view or verify the data.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$generator-&amp;gt;expires_in(60);
my $url = $generator-&amp;gt;get($BUCKET, &amp;quot;$KEY&amp;quot;);
print &amp;quot;$url \n&amp;quot;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can also programmatically read the data directly from the initial connection. This is handy if you have to perform additional processing of the data.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;my $response = $conn-&amp;gt;get(&amp;quot;$BUCKET&amp;quot;, &amp;quot;$KEY&amp;quot;);
my $data     = $response-&amp;gt;object-&amp;gt;data;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Another cool feature is &lt;a href=&#34;http://docs.amazonwebservices.com/AmazonS3/2006-03-01/&#34;&gt;the ability to use BitTorrent to download files from Amazon S3&lt;/a&gt; . You can access any object that has anonymous access privileges via BitTorrent.&lt;/p&gt;

&lt;h4 id=&#34;delete-an-object&#34;&gt;Delete an Object&lt;/h4&gt;

&lt;p&gt;By now you probably have the hang of the process. If you&amp;rsquo;re going to create objects, you&amp;rsquo;re probably going to have to delete them at some point.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$conn-&amp;gt;delete(&amp;quot;$BUCKET&amp;quot;, &amp;quot;$KEY&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;set-access-permissions-and-publish-to-a-website&#34;&gt;Set Access Permissions and Publish to a Website&lt;/h4&gt;

&lt;p&gt;As you may have noticed from the previous examples, all Amazon S3 objects access goes through HTTP. This makes Amazon S3 particularly useful as a online repository. In particular, it&amp;rsquo;s useful to manage and serve website media. You could almost imagine Amazon S3 serving as mini Content Delivery Network for media on your website. This example will demonstrate how to build a very simple online page where the images are served dynamically via Amazon S3.&lt;/p&gt;

&lt;p&gt;The first thing to do us to upload some images and set the ACL permissions to public. I&amp;rsquo;ve modified the previous example with one difference. To make objects publicly readable, include the header &lt;code&gt;x-amz-acl: public-read&lt;/code&gt; with the HTTP PUT request.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;my %headers = (
    &#39;x-amz-acl&#39; =&amp;gt; &#39;public-read&#39;,
);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Additional ACL permissions include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;private (default setting if left blank)&lt;/li&gt;
&lt;li&gt;public-read&lt;/li&gt;
&lt;li&gt;public-read-write&lt;/li&gt;
&lt;li&gt;authenticated-read&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now you know enough to put together a small script that will automatically display all images in the bucket to a web page (you&amp;rsquo;ll probably want to spruce up the formatting).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;...
my $BUCKET   = &amp;quot;foobar&amp;quot;;
my $response = $conn-&amp;gt;list_bucket(&amp;quot;$BUCKET&amp;quot;);

for my $entry (@{$response-&amp;gt;entries}) {
    my $public_url   = $generator-&amp;gt;get($BUCKET, $entry-&amp;gt;{Key});
    my ($url, undef) = split (/\?/, $public_url);
    $images         .= &amp;quot;&amp;lt;img src=\&amp;quot;$url\&amp;quot;&amp;gt;&amp;lt;br /&amp;gt;&amp;quot;;
}
($webpage =  &amp;lt;&amp;lt;&amp;quot;WEBPAGE&amp;quot;);
&amp;lt;html&amp;gt;&amp;lt;body&amp;gt;$images&amp;lt;/body&amp;gt;&amp;lt;/html&amp;gt;
WEBPAGE
print $q-&amp;gt;header();
print $webpage;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To add images to this web page, upload more files into the bucket and they will automatically appear the next time you load the page.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s also simple to link to media one at a time for a webpage. If you examine the HTML generated by this example, you&amp;rsquo;ll see that all Amazon S3 URLs have the basic form &lt;code&gt;http://bucketname.s3.amazon.com/objectname&lt;/code&gt;. Also note that the namespace for buckets is shared with all Amazon S3 users. You may have already picked up on this.&lt;/p&gt;

&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;Amazon S3 is a great tool that can help with the data management needs of all sized organizations by offering cheap and unlimited storage. For personal use, it&amp;rsquo;s a great tool for backups (also good for organizations) and general file storage. It&amp;rsquo;s also a great tool for collaboration. Instead of emailing files around, just upload a file and set the proper access controls &amp;ndash; no more dealing with 10 MB attachment restrictions!&lt;/p&gt;

&lt;p&gt;At &lt;a href=&#34;http://www.sundaymorningrides.com/&#34;&gt;SundayMorningRides.com&lt;/a&gt; we use S3 as part of our web serving infrastructure to reduce the load on our hardware when serving media content.&lt;/p&gt;

&lt;p&gt;When combined with other Amazon Web Services such as SimpleDB (for structured data queries) and Elastic Compute Cloud (for data processing) it&amp;rsquo;s easy to envision a low cost solution for web-scale computing and data management.&lt;/p&gt;

&lt;h4 id=&#34;more-resources-and-references&#34;&gt;More Resources and References&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://aws.amazon.com/s3&#34;&gt;Amazon S3 Homepage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://developer.amazonwebservices.com/&#34;&gt;Amazon Webservices Developer Connection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://developer.amazonwebservices.com/connect/entry.jspa?externalID=133&amp;amp;categoryID=47&#34;&gt;Amazon S3 Library for REST in Perl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://aws.typepad.com/&#34;&gt;Amazon Web Services Blog&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>

